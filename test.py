from flask import Flask, request, jsonify
import openai
import random

app = Flask(__name__)

# Configure OpenAI API key
openai.api_key = "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"

# Predefined themes for quirky prompts
themes = [
    "AI humor",
    "Programming puns",
    "Gaming analogies",
    "Algorithm jokes",
    "Debugging metaphors",
]

# Function to generate a prompt
def generate_prompt(theme):
    base_prompt = f"Generate a quirky, fun, and computer science-themed question for a dating site. Theme: {theme}. Example question: "
    try:
        # Using gpt-3.5-turbo for generating the prompt
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",  # Use a new model
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": base_prompt}
            ],
            max_tokens=50,
            temperature=0.8,
        )
        # Return the message generated by the assistant
        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        return f"Error generating prompt: {str(e)}"

@app.route("/")
def home():
    # Home route that will be accessible at http://127.0.0.1:5000/
    return "Welcome to the CS Dating Prompt API! Use the /generate_prompt endpoint to fetch a quirky prompt."

@app.route("/generate_prompt", methods=["GET"])
def get_prompt():
    # Randomly pick a theme for variety
    theme = random.choice(themes)

    # Optionally accept a user-specified theme
    user_theme = request.args.get("theme")
    if user_theme:
        theme = user_theme

    prompt = generate_prompt(theme)
    return jsonify({"theme": theme, "prompt": prompt})

if __name__ == "__main__":
    app.run(debug=True)
